{"cells":[{"metadata":{},"cell_type":"markdown","source":"# RSNA Intracranial Hemorrhage Detection "},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pydicom\nimport os\nimport random\nimport cv2\nimport tensorflow as tf\nfrom math import ceil\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.layers import Dense\nfrom keras.models import Model, load_model\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.utils import Sequence\nfrom keras.losses import binary_crossentropy\nfrom keras.optimizers import Adam\nfrom sklearn.model_selection import StratifiedShuffleSplit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Seed\nSEED = 42\nnp.random.seed(SEED)\n\n# some constants\nTEST_SIZE = 0.06\nHEIGHT = 224\nWIDTH = 224\nTRAIN_BATCH_SIZE = 32\nVALID_BATCH_SIZE = 16\n\n# Train and Test folders\ninput_folder = '../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/'\npath_train_img = input_folder + 'stage_2_train/'\npath_test_img = input_folder + 'stage_2_test/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(input_folder + 'stage_2_train.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# extract subtype\ntrain_df['sub_type'] = train_df['ID'].apply(lambda x: x.split('_')[-1])\n# extract filename\ntrain_df['file_name'] = train_df['ID'].apply(lambda x: '_'.join(x.split('_')[:2]) + '.dcm')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove duplicates\ntrain_df.drop_duplicates(['Label', 'sub_type', 'file_name'], inplace=True)\ntrain_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of train images availabe:\", len(os.listdir(path_train_img)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_final_df = pd.pivot_table(train_df.drop(columns='ID'), index=\"file_name\", \\\n                                columns=\"sub_type\", values=\"Label\")\ntrain_final_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_final_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Invalid image ID_6431af929.dcm\ntrain_final_df.drop('ID_6431af929.dcm', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_small_df = train_final_df.head(0)\n\nepidural_df = train_final_df[train_final_df.epidural == 1]\nintraparenchymal_df = train_final_df[train_final_df.intraparenchymal == 1]\nintraventricular_df = train_final_df[train_final_df.intraventricular == 1]\nsubarachnoid_df = train_final_df[train_final_df.subarachnoid == 1]\nsubdural_df = train_final_df[train_final_df.subdural == 1]\n\nnon_df=train_final_df[(train_final_df.epidural == 0) & (train_final_df.intraparenchymal == 0) & \\\n                      (train_final_df.intraventricular == 0) & (train_final_df.subarachnoid == 0) & \\\n                      (train_final_df.subdural == 0)]\n\ntrain_small_df = pd.concat([train_small_df,epidural_df[:2000],intraparenchymal_df[:2000],\\\n                            intraventricular_df[:2000],subarachnoid_df[:2000],subdural_df[:2000],\\\n                            non_df[:10000] ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Taken From Gradient and Sigmoid Windowing\n# https://www.kaggle.com/reppic/gradient-sigmoid-windowing\ndef get_dicom_field_value(val):\n    if type(val) == pydicom.multival.MultiValue:\n        return int(val[0])\n    else:\n        return int(val)\n\ndef get_windowing(data):\n    dicom_fields = [data.WindowCenter, data.WindowWidth, \\\n                    data.RescaleSlope, data.RescaleIntercept]\n    return [get_dicom_field_value(x) for x in dicom_fields]\n\ndef get_windowed_image(image, wc, ww, slope, intercept):\n    img = (image*slope +intercept)\n    img_min = wc - ww//2\n    img_max = wc + ww//2\n    img[img<img_min] = img_min\n    img[img>img_max] = img_max\n    return img \n\n\ndef _normalize(img):\n    if img.max() == img.min():\n        return np.zeros(img.shape)\n    return 2 * (img - img.min())/(img.max() - img.min()) - 1\n\ndef _read(path, desired_size=(224, 224)):\n    # 1. read dicom file\n    dcm = pydicom.dcmread(path)\n    \n    # 2. Extract meta data features\n    # window center, window width, slope, intercept\n    window_params = get_windowing(dcm)\n    try:\n        # 3. Generate windowed image\n        img = get_windowed_image(dcm.pixel_array, *window_params)\n    except:\n        img = np.zeros(desired_size)\n\n    img = _normalize(img)\n\n    if desired_size != (512, 512):\n        # resize image\n        img = cv2.resize(img, desired_size, interpolation = cv2.INTER_LINEAR)\n    return img[:,:,np.newaxis]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_read(path_train_img + 'ID_ffff922b9.dcm', (128, 128)).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(\n    _read(path_train_img + 'ID_ffff922b9.dcm', (128, 128))[:, :, 0]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train Data Generator - Used from Stanford website\n# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\nclass TrainDataGenerator(keras.utils.Sequence):\n\n    def __init__(self, dataset, labels, batch_size=16, img_size=(512, 512), img_dir = path_train_img, *args, **kwargs):\n        self.dataset = dataset\n        self.ids = dataset.index\n        self.labels = labels\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.img_dir = img_dir\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(ceil(len(self.ids) / self.batch_size))\n\n    def __getitem__(self, index):\n        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n        X, Y = self.__data_generation(indices)\n        return X, Y\n\n    def on_epoch_end(self):\n        self.indices = np.arange(len(self.ids))\n        np.random.shuffle(self.indices)\n        \n    def __data_generation(self, indices):\n        X = np.empty((self.batch_size, *self.img_size, 3))\n        Y = np.empty((self.batch_size, 6), dtype=np.float32)\n        \n        for i, index in enumerate(indices):\n            ID = self.ids[index]\n            image = _read(self.img_dir + ID, self.img_size)\n            X[i,] = image            \n            Y[i,] = self.labels.iloc[index].values        \n        return X, Y\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Oversampling\n#epidural_df = train_final_df[train_final_df.epidural == 1]\n#train_final_df = pd.concat([train_final_df, epidural_df])\n#print('Train Shape: {}'.format(train_final_df.shape))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"base_model =  ResNet50(weights = 'imagenet', include_top = False, \\\n                                 pooling = 'avg', input_shape = (HEIGHT, WIDTH, 3))\nx = base_model.output\n#x = Dropout(0.125)(x)\noutput_layer = Dense(6, activation = 'sigmoid')(x)\nmodel = Model(inputs=base_model.input, outputs=output_layer)\nmodel.compile(optimizer = Adam(learning_rate = 0.0001), \n                  loss = 'binary_crossentropy',\n                  metrics = ['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mutlilabel stratification\nsplits = StratifiedShuffleSplit(n_splits = 2, test_size = TEST_SIZE, random_state = SEED)\nfile_names = train_small_df.index\nlabels = train_small_df.values\n# Lets take only the first split\nsplit = next(splits.split(file_names, labels))\ntrain_idx = split[0]\nvalid_idx = split[1]\nsubmission_predictions = []\nlen(train_idx), len(valid_idx)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train data generator\ndata_generator_train = TrainDataGenerator(train_small_df.iloc[train_idx], \n                                                train_small_df.iloc[train_idx], \n                                                TRAIN_BATCH_SIZE, \n                                                (WIDTH, HEIGHT))\n\n# validation data generator\ndata_generator_val = TrainDataGenerator(train_small_df.iloc[valid_idx], \n                                            train_small_df.iloc[valid_idx], \n                                            VALID_BATCH_SIZE, \n                                            (WIDTH, HEIGHT))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data_generator_train), len(data_generator_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(generator = data_generator_train,\n                            validation_data = data_generator_val,\n                            epochs = 2,\n                            verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.empty((1, 224, 224, 3))\nX[0, ] = _read(path_train_img + 'ID_000012eaf.dcm', (224, 224))\nplt.imshow(\n    _read(path_train_img + 'ID_000012eaf.dcm', (224, 224))[:, :, 0]\n )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# np.argmax(model.predict(X))\n\ny = model.predict(X)\npred = zip(y.tolist()[0], train_small_df.columns)\nfor i in pred:\n    print(i)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}